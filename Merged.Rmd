---
title: "R Notebook"
output: html_notebook
---
##Introduction
# # As Students of the university of economics in vienna have to be aware of dilemmas that can face any business. Being able to judge a situation facing a company correctly and act accordingly is one of our most important tasks as future graduates. Through this course we have learned many ways to analyze a companies data and make predictions for future scenarios.

#Starting this project thought of different circumstances threatening a company and coming up proper analyzing methods and a way to predict an outcome. One of the biggest factors influencing a company's future is customer Satisfaction. For a business to keep its customer's satisfaction level high or at least stable is no easy task. To get a better look on what issues can influence the satisfaction level, We concentrated on random and anonymous airlines from a dataset provided by kaggle. we further trained our models thru different methods to be able to make a solid prediction for future use.

#Starting this project thought of different circumstances threatening a company and coming up proper analyzing methods and a way to predict an outcome. One of the biggest factors influencing a company's future is customer Satisfaction. For a business to keep its customer's satisfaction level high or at least stable is no easy task. To get a better look on what issues can influence the satisfaction level, We concentrated on random and anonymous airlines from a dataset provided by kaggle. we further trained our models thru different methods to be able to make a solid prediction for future use.

###Variable Declaration
Gender: Gender of the passengers (Female, Male)
Customer Type: The customer type (Loyal customer, disloyal customer)
Age: The actual age of the passengers
Type of Travel: Purpose of the flight of the passengers (Personal Travel, Business Travel)
Class: Travel class in the plane of the passengers (Business, Eco, Eco Plus)
Flight distance: The flight distance of this journey
Inflight wifi service: Satisfaction level of the inflight wifi service (0:Not Applicable;1-5)
Departure/Arrival time convenient: Satisfaction level of Departure/Arrival time convenient
Ease of Online booking: Satisfaction level of online booking
Gate location: Satisfaction level of Gate location
Food and drink: Satisfaction level of Food and drink
Online boarding: Satisfaction level of online boarding
Seat comfort: Satisfaction level of Seat comfort
Inflight entertainment: Satisfaction level of inflight entertainment
On-board service: Satisfaction level of On-board service
Leg room service: Satisfaction level of Leg room service
Baggage handling: Satisfaction level of baggage handlin
Check-in service: Satisfaction level of Check-in service
Inflight service: Satisfaction level of inflight service
Cleanliness: Satisfaction level of Cleanliness
Departure Delay in Minutes: Minutes delayed when departure
Arrival Delay in Minutes: Minutes delayed when Arrival
Satisfaction: Airline satisfaction level(Satisfaction, neutral or dissatisfaction)


```{r}
library(caret)
library(ggplot2)
```

```{r}
train <- read.csv(file = 'train.csv')
test <- read.csv(file = 'test.csv')
```

```{r}
#We downloaded the data splitted as train and test data. We thought that we should bind this two datasets for our first data discovery to see how the data we got looks like and to get a better understanding of the variables.
data <- rbind(train, test)

```

```{r}
head(data)
```

```{r}
str(data)
```


```{r}
summary(data)
```


```{r}
#After summarizing the data we see that we have 393 missing values in 'Arrival.Delay.in.Minutes' so we decided to eliminate the rows containing this missing values in both train and test (da sie nur einen sehr kleinen teil des datensatzes ausmachen).
train <- na.omit(train)
test <- na.omit(test)
```


```{r}
#To simplify the levels of satisfaction we decided to rename them from 'neutral or dissatisfied' to 'no' and 'satisfied' to 'yes'. Since we cannot detect whether a customer was neutral or not satisfied we will not miss any important information.
test$satisfaction <-factor(test$satisfaction, levels = c("neutral or dissatisfied", "satisfied"), labels=c("no", "yes"))
train$satisfaction <- factor(train$satisfaction, levels = c("neutral or dissatisfied", "satisfied"), labels=c("no", "yes"))

```

```{r}
head(train)
```
#to get a first look on how the different variables interact with our satisfaction variable, we created some barchart to visualize their relationship. In first graph put flight distance with our response variable. It looks like the longer the flight distance the more satisfied were the customers.

#the following variabele (Baggage.handling, Inflight.service, Inflight.entertainment, Food.and.drink, On.board.service, Seat.comfort, Cleanliness) have very similar graphs. customers tend to be satisfied more, when the service they recieve  meet their expectations.

#looking at the Type.of.Travel we saw that most of the customers are business travellers and tend to be more satisfied with their flight experience. one reason could be that business travellers fly more often and tend to have a different mindset than others.

```{r}
plot(data$satisfaction ~ data$Flight.Distance)
```

```{r}
plot(data$satisfaction ~ data$Baggage.handling)
```


```{r}
plot(data$satisfaction ~ data$Inflight.service)
```


```{r}
plot(data$satisfaction ~ data$Inflight.entertainment)
```


```{r}
plot(data$satisfaction ~ data$Food.and.drink)
```


```{r}
plot(data$satisfaction ~ data$Type.of.Travel)
```


```{r}
plot(data$satisfaction ~ data$On.board.service)

```


```{r}
plot(data$satisfaction ~ data$Seat.comfort)

```


```{r}
plot(data$satisfaction ~ data$Cleanliness)
```
These boxplots deliver a better visualization of the variables. Most of these plots show a rather positive result. all the shown graphs except cleanliness and food and Drink have a mean of 4. interestingly the boxplots on board service and inflight Entertainment are identical with the mean equalling the 3rd quantile.

```{r}
boxplot(data$Flight.Distance)
```

```{r}
# 1= On board service
# 2= Seat comfort
# 3= Cleanliness
# 4= Inflight Service
# 5= Inflight Entertainment
# 6= Food and Drink
# 7= Baggage handling
boxplot(data$On.board.service, data$Seat.comfort, data$Cleanliness, data$Inflight.service, data$Inflight.entertainment, data$Food.and.drink, data$Baggage.handling)
```



```{r}
set.seed(4567)
```
#Christian 
#After analyzing the first inspections on our dataset we initiated our further evaluation with a generalized linear model. It fits in linear, logistic regression models and in cases where the response variable has an error distribution that is non-normal. As we can see, the final values used for the model were alpha = 0.1 and lambda = 0.004989601.

```{r}
glm_model <- train(satisfaction~. -X -id, data = train, method = "glmnet", trControl = trainControl(method="cv",number=10), preProcess= c("center", "scale"))
glm_model
```
#Here we have a nice visualisation of our model. 
```{r}
plot(glm_model)
```
#And now we are using the predict function for our model.
```{r}
predicted_logistic <- predict(glm_model, test)
```

```{r}
table_glm <- table(predicted_logistic, test$satisfaction)
table_glm
```

```{r}
confusionMatrixLogistic <- confusionMatrix(table_glm)
```
#So the decision tree belongs to the tree-based classification methods. The are not just solving classification problems, but also regression problems. Important here to mention is that we just use one predictor at a node as a splitting variable.

```{r}
#Model Building Tree
tree <- train(
          satisfaction~. -X -id,
          train,
          method = "rpart",
          trControl = trainControl(
          method = "cv",
          number = 10,
        )
)
```
#We obtained here an accuracy of 85% which is really good.

```{r}
plot(tree)
```

#Now we are feeding again the prediction function with our data.
```{r}
predicted_tree <- predict(tree, test)
```

```{r}
table_tree <- table(predicted_tree, test$satisfaction)
table_tree
```

```{r}
confusionMatrixTree <- confusionMatrix(table_tree)
```


```{r}
#KNN 
tcon <- trainControl(method = 'cv', number = 10, verboseIter = TRUE)
knn_model <- train(satisfaction~. -X -id,
                   train,
                   method = 'knn',
                   trControl = tcon
                   )
```

```{r}
summary(knn_model)
```


```{r}
predicted_knn <- predict(knn_model, test)
predicted_knn
```

```{r}
table_knn <- table(predicted_knn, test$satisfaction)
table_knn
```
```{r}
confusionMatrixKNN <- confusionMatrix(table_knn)
```


```{r}
nnet = train(satisfaction~. -X -id, data = train, method = "nnet", trControl = trainControl(method="cv",number=10))
```

```{r}
nnet
```


```{r}
summary(nnet)
```


```{r}
pred_nnet <- predict(nnet, test)
pred_nnet
```


```{r}
table_nnet <- table(pred_nnet, test$satisfaction)
table_nnet
```

```{r}
confusionMatrixNNET <- confusionMatrix(table_nnet)
```


```{r}
svm_tr_control = trainControl(method = "repeatedcv", number = 10,verboseIter = TRUE)
fit_model.svm <- train(satisfaction ~ . -X -id, train[1:5000, ], method = "svmLinear", trControl = svm_tr_control, na.action = na.pass, metric = 'Accuracy')
```

```{r}
fit_model.svm
```

```{r}
summary(model.svm)
```


```{r}
pred.svm <- predict(model.svm, test)
```


```{r}
tab.svm <- table(pred.svm, test$satisfaction)
tab.svm
```

```{r}
confusionMatrixSVM <- confusionMatrix(tab.svm)
```


```{r}
acc <- c(acc.svm = sum(diag(tab.svm))/sum(tab.svm)) ## accuracy
        
acc
```


```{r}
rec <- c(rec.svm = tab.svm[2,2]/(tab.svm[1,2] + tab.svm[2,2]))
        
rec
```


```{r}
prec <- c(prec.svm = tab.svm[2,2]/(tab.svm[2,1] + tab.svm[2,2]))

prec 
```

```{r}

model.nb <- train(
                satisfaction ~. -X -id,
                train,
                method = "naive_bayes",
                trControl = trainControl(
                    method = "cv",
                    number = 10,
                  )
              )

```


```{r}
summary(model.nb)
```


```{r}
pred.nb <- predict(model.nb, test, 
                type = "raw")
pred.nb

```

```{r}
table.nb <- table(pred.nb, test$satisfaction)
table.nb
```
```{r}
confusionMatrixNV <- confusionMatrix(table.nb)
```



```{r}
# install.packages('ranger')
# library('ranger')
model_forest <- train(
            satisfaction~. -X -id,
            data = train,
            method = 'ranger',
            trControl = tcon
)
```

```{r}
model_forest

```


```{r}
predicted_forest <- predict(model_forest, test)
predicted_forest
```

```{r}
table_forest <- table(predicted_forest, test$satisfaction)
table_forest
```

```{r}
confusionMatrixForest <- confusionMatrix(table_forest)
```

acc <- c(acc.svm = sum(diag(tab.svm))/sum(tab.svm))
        
rec <- c(rec.svm = tab.svm[2,2]/(tab.svm[1,2] + tab.svm[2,2]))
        
prec <- c(prec.svm = tab.svm[2,2]/(tab.svm[2,1] + tab.svm[2,2]))

```{r}
# install.packages('caTools')
# library(caTools)

```


```{r}
list_of_tables <- list(table_knn, table_nnet, tab.svm, table_glm, table_tree, table.nb, table_forest)
list_of_pred <- list(predicted_knn, pred_nnet, pred.svm, predicted_logistic, predicted_tree, pred.nb)
factor_satisfaction <- factor(test$satisfaction)
confusionMatrixModels <- list()


modelNames <- function() {
    for (j in list_of_tables) {
       confusionMatrixModels <- confusionMatrix(j)
      print(confusionMatrixModels, digits = 8)
    }
}


```

```{r}
modelNames()
```

```{r}
list_confusion_matrixes <- 
```


```{r}
naive_bayes_importance <- varImp(model.nb)
plot(naive_bayes_importance)
```

```{r}
fit_model.nb2 <- train(
                satisfaction ~. -X -id -Gender - Departure.Arrival.time.convenient - Departure.Delay.in.Minutes - Arrival.Delay.in.Minutes,
                train,
                method = "naive_bayes",
                metric = 'Accuracy',
                trControl = trainControl(
                    method = "cv",
                    number = 10,
                  )
              )
```


```{r}
fit_model.nb2
```


```{r}
confusionMatrix(table.nb)
```

```{r}
predicted_model_nb2 <- predict(model.nb2, test)
```


```{r}
table_model_nb2 <- table(predicted_model_nb2, test$satisfaction)
```

```{r}
#      Sensitivity : 0.8263                 
   #          Specificity : 0.9270                 
   #       Pos Pred Value : 0.9353                 
   #       Neg Pred Value : 0.8067                 
   #           Prevalence : 0.5611                 
   #       Detection Rate : 0.4636                 
   # Detection Prevalence : 0.4957                 
   #    Balanced Accuracy : 0.8766  
# 
# pred.nb                   neutral or dissatisfied satisfied
#   neutral or dissatisfied                   12004       830
#   satisfied                                  2524     10535


confusionMatrix(table_model_nb2)
```


```{r}
results <- resamples(list(
  svm = fit_model.svm,
  nb = fit_model.nb2
))
```

```{r}
ls()
```

```{r}
print(results)
```


```{r}
confusionMatrix(table_nnet)
```
```{r}
install.packages("caTools")

```

```{r}
library(caTools)
```

```{r}
colAUC(as.numeric(pred.nb),test$satisfaction, plotROC= TRUE )
```


```{r}
colAUC(as.numeric(predicted_knn),test$satisfaction, plotROC= TRUE )
```
```{r}
colAUC(as.numeric(predicted_logistic),test$satisfaction, plotROC= TRUE )
```


```{r}
colAUC(as.numeric(predicted_tree),test$satisfaction, plotROC= TRUE )
```


```{r}
colAUC(as.numeric(pred.svm),test$satisfaction, plotROC= TRUE )
```
```{r}
colAUC(as.numeric(pred_nnet),test$satisfaction, plotROC= TRUE )
```
```{r}
colAUC(as.numeric(predicted_forest),test$satisfaction, plotROC= TRUE )
```
```{r}
forest_accuracy <- confusionMatrixForest$overall["Accuracy"]
```

```{r}
knn_accuracy <- confusionMatrixKNN$overall["Accuracy"]
```

```{r}
logistic_accuracy <- confusionMatrixLogistic$overall["Accuracy"]
```

```{r}
nnet_accuracy <- confusionMatrixNNET$overall["Accuracy"]
```


```{r}
svm_accuracy <- confusionMatrixSVM$overall["Accuracy"]
```

```{r}
tree_accuracy <- confusionMatrixTree$overall["Accuracy"]
```

```{r}
nv_accuracy <- confusionMatrixNV$overall["Accuracy"]
```

```{r}
list_of_matrixes <- list(forest_accuracy, knn_accuracy, logistic_accuracy, nnet_accuracy, svm_accuracy, tree_accuracy, nv_accuracy)
```


```{r}
as.numeric(list_of_matrixes)
```

```{r}
```

```{r}
dataOfModels <- data.frame(
  models=c("Forest","KNN","Logistic","NNET","SVM","Tree", "NB") ,  
  accuracy=as.numeric(list_of_matrixes)
  )
```


```{r}
ggplot(dataOfModels, aes(x=models, y=accuracy)) + 
  geom_bar(stat = "identity", color="blue", fill=rgb(0.1,0.4,0.5,0.7))

```






